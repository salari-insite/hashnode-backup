---
title: "The Matrix Is Everywhere: Linear Algebra Concepts Relevant to Computer Science"
slug: the-matrix-is-everywhere-linear-algebra-concepts-relevant-to-computer-science
cover: https://cdn.hashnode.com/res/hashnode/image/stock/unsplash/iar-afB0QQw/upload/a17458d20a3a815e5372c9f31a2d811e.jpeg

---

While linear algebra originated as a branch of "pure mathematics," its applications have since expanded significantly beyond the mathematical domain. In this article, I'll go in-depth on explaining the core linear algebra concepts and theories that play a significant role in computer science.

---

# Introduction

**This article is part of a series called "Log Base Two"; this series is dedicated to exploring the intricate relationship between mathematics and computer science.**

Just to give a bit of background on my experience in math, I've **excelled** in a total of 10 college courses in math:

1. Single-variable differential calculus
    
2. Single-variable integral calculus
    
3. Multi-variable differential and integral calculus
    
4. Multi-variable differential and integral calculus of vector-valued functions
    
5. Linear Algebra
    
6. Differential equations
    
7. Probability and statistics
    
8. Data analysis using R programming language
    
9. Multivariate statistics
    
10. Discrete math
    

For a large majority of those 10 classes, I ended up with A's.

Although, before college, I struggled a lot with math in the classroom, even though math had always been my favorite subject since I was in elementary school. I found it hard to truly grasp the concepts taught because my high school teachers were too focused on skill assessment. Instead of focusing on the actual concept being taught, I was too worried about how I was going to pass the test the following week.

Once I got to college, I realized that your math grade (or any grade for that matter) truly doesn't define your potential. Further, I'd argue that your success in math *education* is heavily influenced by the quality of the teacher/professor's teaching.

My mission with this series is to show other people that math isn't so scary if you break down mathematical concepts into digestible bouts of information and investigate use cases of math in your primary field of interest (in this case, computer science). Along the way, I hope to also supplement your math education with quality content. I believe that **everyone** is capable of learning and truly loving mathematics.

**New articles in this series are posted every Thursday. If you have any suggestions for a specific topic I should write about, please comment it down below!**

Stay tuned for next week's article where I explain the use of eigenvalues and eigenvectors in machine learning algorithms!

Without further ado, let's get to today's article.

---

# What Even is Linear Algebra?

Linear algebra is a subfield of mathematics that concentrates on linear systems, matrices, and vectors. Through the employment of these three fundamental elements, a multitude of advancements have been achieved in various domains, both within and beyond the sphere of mathematics.

## Why Haven't I Heard About Linear Algebra Before?

If you're still at the beginning of your computer science journey, you might've not been exposed to linear algebra quite yet.

Typically, the first opportunity to take a course in linear algebra is in your 2nd or 3rd year of college. Additionally, colleges usually require you to pass single-variable calculus before being able to enroll in linear algebra.

On top of this, most non-STEM majors in college don't require students to pass any college-level math past single-variable calculus and statistics.

The funny thing is that linear algebra isn't *harder* than calculus. In fact, A majority of my classmates in university, myself included, believe that linear algebra is a bit *easier* than calculus.

Also, linear algebra doesn't directly use any tools or concepts from calculus, so you can't even make the argument that you first need to gain prerequisite information from calculus to understand linear algebra.

So if linear algebra isn't harder than calculus, and there's no prerequisite information gained from calculus, then why does it seem so exclusive and "higher level"?

While I don't have an official answer, I have an opinion as to why this is the case.

I believe that it comes down to two main factors:

* Linear algebra's industrial uses are not as widespread as the branches of math that are taught before it
    
    * While **both** calculus and linear algebra are pretty much only used in STEM and a few other industries (finance, economics, some arts), their uses within those industries are not equal
        
* Linear algebra is a "mature" math
    
    * I know I said that linear algebra is sometimes seen as easier than calculus, but linear algebra's *concepts* are much more abstract than concepts in single-variable calculus
        

With all that being said, there's no problem with getting a head start on learning linear algebra if you're still in school right now.

And if you're going the self-taught route with computer science, then all the more reason to self-teach the math used in computer science!

---

# Key Linear Algebra Concepts Used in Computer Science

I've carefully curated a list of 9 concepts in linear algebra that are used across various branches of computer science including machine learning, computer graphics, cryptography, image processing, information theory, and much more.

For each of these concepts, I'll provide enough general information so you can understand the big picture, and I'll also mention an example of a branch of computer science that uses the concept.

Also, I ordered the concepts in chronological order to have the concepts build on top of each other and improve the flow of the article.

For reference, here are the concepts that I'll be covering:

* **Linear systems**
    
* **Matrices and Gaussian elimination**
    
* **Vectors and vector spaces**
    
* **Orthogonality**
    
* **Determinants**
    
* **Eigenvalues and eigenvectors**
    
* **Diagonalization and symmetric matrices**
    
* **Linear transformations**
    
* **Singular value decomposition**
    

## I. Linear systems

One application of linear systems is in **numerical analysis**. Numerical analysis involves using algorithms that can be used to find approximate numerical solutions to problems where the exact numerical solution is impossible to solve or is too complicated to solve. For instance, if you're trying to solve a problem that has too many variables

A linear system can be defined as an assembly of multiple linear equations that share a common set of variables. These equations are interconnected, and their solutions are represented by the values of the variables that simultaneously satisfy all the equations within the system.

### Linear equations

A linear equation is an equation that consists of *n* variables each with a degree of 1.

The general form of a linear equation is:

$$a_1 x_1 + a_2 x_2 + \ldots + a_n x_n = b$$

The 3 main components of a linear equation are:

* a set of coefficients
    

$$\{a_1, a_2, \ldots, a_n\}$$

* a set of variables
    

$$\{x_1, x_2, \ldots, x_n\}$$

* a constant *b*
    

In linear systems of equations, each equation contains the same set of variables but doesn't necessarily have the same set of coefficients.

Putting together a system of *m* linear equations takes the general form:

$$a_{11} x_1 + a_{12} x_2 + \ldots + a_{1n} x_n = b_1$$

$$a_{21} x_1 + a_{22} x_2 + \ldots + a_{2n} x_n = b_2$$

$$\vdots$$

$$a_{m1} x_1 + a_{m2} x_2 + \ldots + a_{mn} x_n = b_m$$

### Simultaneous solution

The main idea behind a system of equations is that all equations within the system can be solved *simultaneously*.

By doing so, it becomes possible to find a unique solution, or a set of solutions, that satisfies all the given equations, thereby providing a comprehensive understanding of the problem at hand.

## Matrices and Gaussian elimination

## Vectors and vector spaces

## Orthogonality

## Determinants

## Eigenvalues and eigenvectors

## Diagonalization and symmetric matrices

## Linear transformations

## Singular value decomposition

## Computer Graphics and Image Processing

### Geometric transformations

### Translation

### Scaling

### Rotation

### 3D graphics and projection

### Image processing techniques

### Filtering

### Edge detection

### Compression

## Machine Learning and Data Science

### Feature representation and dimensionality reduction

### Principal Component Analysis (PCA)

### Singular Value Decomposition (SVD)

### Linear regression and optimization

### Recommender systems and collaborative filtering

## Network Analysis and Graph Theory

### Adjacency and incidence matrices

### Graph algorithms

### Shortest path

### Maximum flow

### Spectral graph theory and clustering

## Cryptography and Error-Correcting Codes

### Encryption and decryption using linear algebra

### Error detection and correction

### Hamming codes

### Reed-Solomon codes

## Quantum Computing

### Quantum bits (qubits) and quantum gates

### Quantum algorithms

### Shor's algorithm

### Grover's algorithm

## Conclusion

### Recap of linear algebra applications in computer science

### Future prospects and challenges

### Encouragement for further study and exploration

---